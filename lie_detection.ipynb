{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "    return resized\n",
    "\n",
    "def get_face_from_image(img):\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    face = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face.detectMultiScale(gray, 1.2, 5)\n",
    "    return (True, faces[0]) if len(faces)>0 else (False, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_plot(y_true, y_pred, labels=['deceptive', 'truthful'], title='Confusion Matrix'):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max()/2  \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if (cm[i, j] > thresh) else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predited label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id  OtherGestures  Smile  Laugh  Scowl  \\\n",
      "0      trial_lie_001.mp4              1      0      0      0   \n",
      "1      trial_lie_002.mp4              1      0      0      0   \n",
      "2      trial_lie_003.mp4              1      0      0      0   \n",
      "3      trial_lie_004.mp4              1      0      0      0   \n",
      "4      trial_lie_005.mp4              1      0      0      0   \n",
      "..                   ...            ...    ...    ...    ...   \n",
      "116  trial_truth_056.mp4              1      0      0      0   \n",
      "117  trial_truth_057.mp4              1      0      0      0   \n",
      "118  trial_truth_058.mp4              1      0      0      0   \n",
      "119  trial_truth_059.mp4              0      0      0      1   \n",
      "120  trial_truth_060.mp4              0      1      0      0   \n",
      "\n",
      "     otherEyebrowMovement  Frown  Raise  OtherEyeMovements  Close-R  ...  \\\n",
      "0                       1      0      0                  1        0  ...   \n",
      "1                       0      1      0                  1        0  ...   \n",
      "2                       0      1      0                  0        1  ...   \n",
      "3                       1      0      0                  1        0  ...   \n",
      "4                       0      1      0                  1        0  ...   \n",
      "..                    ...    ...    ...                ...      ...  ...   \n",
      "116                     1      0      0                  1        0  ...   \n",
      "117                     0      0      1                  0        1  ...   \n",
      "118                     0      0      1                  0        1  ...   \n",
      "119                     0      0      1                  0        1  ...   \n",
      "120                     0      0      1                  1        0  ...   \n",
      "\n",
      "     forwardHead  downRHead  singleHand  bothHands  otherHandM  complexHandM  \\\n",
      "0              0          0           0          0           1             0   \n",
      "1              0          0           0          1           0             1   \n",
      "2              0          0           0          0           1             0   \n",
      "3              0          1           0          0           1             0   \n",
      "4              0          0           1          0           0             0   \n",
      "..           ...        ...         ...        ...         ...           ...   \n",
      "116            0          0           1          0           0             0   \n",
      "117            0          1           0          0           1             0   \n",
      "118            0          1           0          0           1             0   \n",
      "119            0          0           0          0           1             0   \n",
      "120            0          0           0          0           1             0   \n",
      "\n",
      "     sidewaysHand  downHands  upHands      class  \n",
      "0               0          0        0  deceptive  \n",
      "1               0          0        0  deceptive  \n",
      "2               0          0        0  deceptive  \n",
      "3               0          0        0  deceptive  \n",
      "4               0          0        0  deceptive  \n",
      "..            ...        ...      ...        ...  \n",
      "116             0          0        1   truthful  \n",
      "117             0          0        0   truthful  \n",
      "118             0          0        0   truthful  \n",
      "119             0          0        0   truthful  \n",
      "120             0          0        0   truthful  \n",
      "\n",
      "[121 rows x 41 columns]\n",
      "{'trial_lie_001.mp4': 0, 'trial_lie_002.mp4': 0, 'trial_lie_003.mp4': 0, 'trial_lie_004.mp4': 0, 'trial_lie_005.mp4': 0, 'trial_lie_006.mp4': 0, 'trial_lie_007.mp4': 0, 'trial_lie_008.mp4': 0, 'trial_lie_009.mp4': 0, 'trial_lie_010.mp4': 0, 'trial_lie_011.mp4': 0, 'trial_lie_012.mp4': 0, 'trial_lie_013.mp4': 0, 'trial_lie_014.mp4': 0, 'trial_lie_015.mp4': 0, 'trial_lie_016.mp4': 0, 'trial_lie_017.mp4': 0, 'trial_lie_018.mp4': 0, 'trial_lie_019.mp4': 0, 'trial_lie_020.mp4': 0, 'trial_lie_021.mp4': 0, 'trial_lie_022.mp4': 0, 'trial_lie_023.mp4': 0, 'trial_lie_024.mp4': 0, 'trial_lie_025.mp4': 0, 'trial_lie_026.mp4': 0, 'trial_lie_027.mp4': 0, 'trial_lie_028.mp4': 0, 'trial_lie_029.mp4': 0, 'trial_lie_030.mp4': 0, 'trial_lie_031.mp4': 0, 'trial_lie_032.mp4': 0, 'trial_lie_033.mp4': 0, 'trial_lie_034.mp4': 0, 'trial_lie_035.mp4': 0, 'trial_lie_036.mp4': 0, 'trial_lie_037.mp4': 0, 'trial_lie_038.mp4': 0, 'trial_lie_039.mp4': 0, 'trial_lie_040.mp4': 0, 'trial_lie_041.mp4': 0, 'trial_lie_042.mp4': 0, 'trial_lie_043.mp4': 0, 'trial_lie_044.mp4': 0, 'trial_lie_045.mp4': 0, 'trial_lie_046.mp4': 0, 'trial_lie_047.mp4': 0, 'trial_lie_048.mp4': 0, 'trial_lie_049.mp4': 0, 'trial_lie_050.mp4': 0, 'trial_lie_051.mp4': 0, 'trial_lie_052.mp4': 0, 'trial_lie_053.mp4': 0, 'trial_lie_054.mp4': 0, 'trial_lie_055.mp4': 0, 'trial_lie_056.mp4': 0, 'trial_lie_057.mp4': 0, 'trial_lie_058.mp4': 0, 'trial_lie_059.mp4': 0, 'trial_lie_060.mp4': 0, 'trial_lie_061.mp4': 0, 'trial_truth_001.mp4': 1, 'trial_truth_002.mp4': 1, 'trial_truth_003.mp4': 1, 'trial_truth_004.mp4': 1, 'trial_truth_005.mp4': 1, 'trial_truth_006.mp4': 1, 'trial_truth_007.mp4': 1, 'trial_truth_008.mp4': 1, 'trial_truth_009.mp4': 1, 'trial_truth_010.mp4': 1, 'trial_truth_011.mp4': 1, 'trial_truth_012.mp4': 1, 'trial_truth_013.mp4': 1, 'trial_truth_014.mp4': 1, 'trial_truth_015.mp4': 1, 'trial_truth_016.mp4': 1, 'trial_truth_017.mp4': 1, 'trial_truth_018.mp4': 1, 'trial_truth_019.mp4': 1, 'trial_truth_020.mp4': 1, 'trial_truth_021.mp4': 1, 'trial_truth_022.mp4': 1, 'trial_truth_023.mp4': 1, 'trial_truth_024.mp4': 1, 'trial_truth_025.mp4': 1, 'trial_truth_026.mp4': 1, 'trial_truth_027.mp4': 1, 'trial_truth_028.mp4': 1, 'trial_truth_029.mp4': 1, 'trial_truth_030.mp4': 1, 'trial_truth_031.mp4': 1, 'trial_truth_032.mp4': 1, 'trial_truth_033.mp4': 1, 'trial_truth_034.mp4': 1, 'trial_truth_035.mp4': 1, 'trial_truth_036.mp4': 1, 'trial_truth_037.mp4': 1, 'trial_truth_038.mp4': 1, 'trial_truth_039.mp4': 1, 'trial_truth_040.mp4': 1, 'trial_truth_041.mp4': 1, 'trial_truth_042.mp4': 1, 'trial_truth_043.mp4': 1, 'trial_truth_044.mp4': 1, 'trial_truth_045.mp4': 1, 'trial_truth_046.mp4': 1, 'trial_truth_047.mp4': 1, 'trial_truth_048.mp4': 1, 'trial_truth_049.mp4': 1, 'trial_truth_050.mp4': 1, 'trial_truth_051.mp4': 1, 'trial_truth_052.mp4': 1, 'trial_truth_053.mp4': 1, 'trial_truth_054.mp4': 1, 'trial_truth_055.mp4': 1, 'trial_truth_056.mp4': 1, 'trial_truth_057.mp4': 1, 'trial_truth_058.mp4': 1, 'trial_truth_059.mp4': 1, 'trial_truth_060.mp4': 1}\n"
     ]
    }
   ],
   "source": [
    "video_inf_path = \"D:/Miscellaneous/J-comp/MLA/RLT/Annotation/Labels.csv\"\n",
    "\n",
    "video_data = pd.read_csv(video_inf_path)\n",
    "print(video_data)\n",
    "video_filenames = video_data['id'].tolist()\n",
    "labels = [1 if x == 'truthful' else 0 for x in video_data['class'].tolist()]\n",
    "video_dict = dict(zip(video_filenames, labels))\n",
    "print(video_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"D:/Miscellaneous/J-comp/MLA/RLT/\"\n",
    "video_path = \"D:/Miscellaneous/J-comp/MLA/RLT/Video_chunks/\"\n",
    "whole_video_path = \"D:/Miscellaneous/J-comp/MLA/RLT/Whole_Videos/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_lie_001.mp4 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m count\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     51\u001b[0m \u001b[39mprint\u001b[39m(k, v)\n\u001b[1;32m---> 52\u001b[0m xi \u001b[39m=\u001b[39m read_video(k)\n\u001b[0;32m     53\u001b[0m X\u001b[39m.\u001b[39mappend(xi)\n\u001b[0;32m     54\u001b[0m y\u001b[39m.\u001b[39mappend(v)\n",
      "Cell \u001b[1;32mIn [9], line 19\u001b[0m, in \u001b[0;36mread_video\u001b[1;34m(filename, max_frames)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mif\u001b[39;00m ret:\n\u001b[1;32m---> 19\u001b[0m     (detected, rect) \u001b[39m=\u001b[39m get_face_from_image(frame_image)\n\u001b[0;32m     20\u001b[0m     x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39m48\u001b[39m\u001b[39m*\u001b[39m\u001b[39m48\u001b[39m)\n\u001b[0;32m     22\u001b[0m     \u001b[39mif\u001b[39;00m detected:\n",
      "Cell \u001b[1;32mIn [3], line 21\u001b[0m, in \u001b[0;36mget_face_from_image\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_face_from_image\u001b[39m(img):\n\u001b[0;32m     20\u001b[0m     gray\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mcvtColor(img,cv2\u001b[39m.\u001b[39mCOLOR_RGB2GRAY)\n\u001b[1;32m---> 21\u001b[0m     face \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mCascadeClassifier(cv2\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mhaarcascades \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mhaarcascade_frontalface_default.xml\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     22\u001b[0m     faces \u001b[39m=\u001b[39m face\u001b[39m.\u001b[39mdetectMultiScale(gray, \u001b[39m1.2\u001b[39m, \u001b[39m5\u001b[39m)\n\u001b[0;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, faces[\u001b[39m0\u001b[39m]) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(faces)\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def preprocess_image(img):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    cropped_img = np.expand_dims(np.expand_dims(cv2.resize(gray_img, (48, 48)), -1), 0)\n",
    "    cv2.normalize(cropped_img, cropped_img, alpha=0, beta=1, norm_type=cv2.NORM_L2, dtype=cv2.CV_32F)\n",
    "    return cropped_img\n",
    "\n",
    "def read_video(filename, max_frames=300):\n",
    "    cam = cv2.VideoCapture(video_path + filename)\n",
    "    current_frame = 0\n",
    "    xdata = np.zeros((max_frames, 48*48))\n",
    "\n",
    "    while(True):\n",
    "        ret, frame_image = cam.read()\n",
    "        \n",
    "        if current_frame >= max_frames:\n",
    "            break\n",
    "\n",
    "        if ret:\n",
    "            (detected, rect) = get_face_from_image(frame_image)\n",
    "            x = np.zeros(48*48)\n",
    "\n",
    "            if detected:\n",
    "                (x, y, w, h) = rect\n",
    "                cropped_face = frame_image[y:y+h, x:x+w]\n",
    "                cropped_img = preprocess_image(cropped_face)\n",
    "                x = cropped_img.flatten()\n",
    "            \n",
    "            xdata[current_frame, :] = x\n",
    "            current_frame+=1\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return xdata\n",
    "\n",
    "def saveData(X, y):\n",
    "    X = np.asarray(X, dtype=object)\n",
    "    y = np.asarray(y, dtype=object)\n",
    "    np.save(dataset_path + 'f_files/' + 'faces_dataX', X)\n",
    "    np.save(dataset_path + 'f_files/' + 'faces_labels', y)\n",
    "    print(f\"Saving X and y of shape {X.shape}, {y.shape}, respectively.\")\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "count = 0\n",
    "for (k, v) in video_dict.items():\n",
    "    count+=1\n",
    "    print(k, v)\n",
    "    xi = read_video(k)\n",
    "    X.append(xi)\n",
    "    y.append(v)\n",
    "    if count % 5 == 0:\n",
    "        saveData(X, y)\n",
    "\n",
    "saveData(X, y)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data (121, 300, 2304) (121,)\n"
     ]
    }
   ],
   "source": [
    "X = np.load(dataset_path + \"f_files/faces_dataX.npy\", allow_pickle=True)\n",
    "y = np.load(dataset_path + \"f_files/faces_labels.npy\", allow_pickle=True)\n",
    "print('Loaded data', X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 300, 48, 48, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.reshape(X,(X.shape[0], X.shape[1], 48, 48))\n",
    "X = np.expand_dims(X, -1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import initializers\n",
    "from keras.losses import binary_crossentropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Masking, GRU\n",
    "from keras.layers import Conv1D, Conv2D, Conv3D, MaxPooling1D, MaxPooling2D, MaxPooling3D, BatchNormalization\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 7983767418283203032\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 2254700544\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 10007922531149613348\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_names total: 25\n",
      "10/10 [==============================] - 2s 20ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "10/10 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model(\"C:/Users/L3NOVO/AppData/Roaming/jupyter/kernels/mlajcomp/fer_optimal.h5\")\n",
    "\n",
    "layer_names = [layer.name for layer in loaded_model.layers]\n",
    "layer_outputs = [layer.output for layer in loaded_model.layers]\n",
    "print(f\"layer_names total: {len(layer_names)}\")\n",
    "\n",
    "X = np.array(X, dtype=float)\n",
    "\n",
    "X -= np.mean(X, axis=0)\n",
    "X /= np.std(X, axis=0)\n",
    "\n",
    "encoding_model = Model(inputs = loaded_model.inputs, outputs = layer_outputs[23])\n",
    "\n",
    "X_cnn = np.zeros((X.shape[0], X.shape[1], 512))\n",
    "i = 0\n",
    "\n",
    "for (xi, yi) in zip(X, y):\n",
    "    predictedX = encoding_model.predict(xi)\n",
    "    X_cnn[i] = predictedX\n",
    "    i+=1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cnn, y, test_size=0.1, random_state=1)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=7)\n",
    "\n",
    "np.save(dataset_path + \"mod_files/\" + \"modXtest\", X_test)\n",
    "np.save(dataset_path + \"mod_files/\" + \"modytest\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 300, 512) (97,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "m = X_train.shape[0]\n",
    "Tx = X_train.shape[1]\n",
    "dims = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 300, 512)]        0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 72, 196)           1505476   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 5, 196)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 5, 196)           784       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 5, 196)            0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 196)            0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 5, 256)            348672    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5, 256)            0         \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 5, 256)            394752    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, 256)            0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 5, 256)           1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5, 1)              257       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,250,965\n",
      "Trainable params: 2,250,061\n",
      "Non-trainable params: 904\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_gru_model(input_shape):\n",
    "    X_input = Input(shape=input_shape)\n",
    "    X = Conv1D(filters=196, kernel_size=15, strides=4)(X_input)\n",
    "    X = MaxPooling1D(pool_size=30, strides=15, padding='same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    \n",
    "    X = GRU(units=256, return_sequences=True)(X)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    #X = BatchNormalization()(X)\n",
    "\n",
    "    # X = GRU(units=256, return_sequences=True)(X)\n",
    "    # X = Dropout(rate=0.8)(X)\n",
    "    # X = BatchNormalization()(X)\n",
    "\n",
    "    X = GRU(units=256, return_sequences=True)(X)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    X = Dense(1, activation=\"sigmoid\")(X)\n",
    "    X = Flatten()(X)\n",
    "\n",
    "    model = Model(inputs=X_input, outputs=X)\n",
    "\n",
    "    return model\n",
    "\n",
    "gru_model = create_gru_model(input_shape=(Tx, dims))\n",
    "gru_model.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.8531 - accuracy: 0.1856 - val_loss: 0.5609 - val_accuracy: 0.8182\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.8843 - accuracy: 0.1856 - val_loss: 0.5317 - val_accuracy: 0.8182\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7991 - accuracy: 0.1959 - val_loss: 0.5094 - val_accuracy: 0.8182\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.8259 - accuracy: 0.2680 - val_loss: 0.5040 - val_accuracy: 0.8182\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.8164 - accuracy: 0.2577 - val_loss: 0.5075 - val_accuracy: 0.8182\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.8366 - accuracy: 0.2165 - val_loss: 0.5084 - val_accuracy: 0.8182\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7784 - accuracy: 0.1753 - val_loss: 0.5095 - val_accuracy: 0.8182\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8451 - accuracy: 0.2371 - val_loss: 0.5108 - val_accuracy: 0.8182\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7842 - accuracy: 0.1856 - val_loss: 0.5109 - val_accuracy: 0.8182\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7384 - accuracy: 0.1546 - val_loss: 0.5125 - val_accuracy: 0.8182\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.6914 - accuracy: 0.2577 - val_loss: 0.5140 - val_accuracy: 0.8182\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6691 - accuracy: 0.3299 - val_loss: 0.5173 - val_accuracy: 0.8182\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.6590 - accuracy: 0.1856 - val_loss: 0.5229 - val_accuracy: 0.8182\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.6210 - accuracy: 0.2680 - val_loss: 0.5292 - val_accuracy: 0.8182\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.6365 - accuracy: 0.1753 - val_loss: 0.5366 - val_accuracy: 0.7273\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.5442 - accuracy: 0.2062 - val_loss: 0.5456 - val_accuracy: 0.6364\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.5825 - accuracy: 0.2268 - val_loss: 0.5567 - val_accuracy: 0.5455\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.5156 - accuracy: 0.3505 - val_loss: 0.5721 - val_accuracy: 0.5455\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4776 - accuracy: 0.2784 - val_loss: 0.5863 - val_accuracy: 0.5455\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4826 - accuracy: 0.3711 - val_loss: 0.5990 - val_accuracy: 0.5455\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4400 - accuracy: 0.3814 - val_loss: 0.6158 - val_accuracy: 0.5455\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.4139 - accuracy: 0.3402 - val_loss: 0.6471 - val_accuracy: 0.5455\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3925 - accuracy: 0.3505 - val_loss: 0.6858 - val_accuracy: 0.5455\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3286 - accuracy: 0.3711 - val_loss: 0.7216 - val_accuracy: 0.5455\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.3387 - accuracy: 0.3196 - val_loss: 0.7511 - val_accuracy: 0.4545\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.3547 - accuracy: 0.3505 - val_loss: 0.7854 - val_accuracy: 0.4545\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.3424 - accuracy: 0.3093 - val_loss: 0.8144 - val_accuracy: 0.4545\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3586 - accuracy: 0.3608 - val_loss: 0.8348 - val_accuracy: 0.4545\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.2851 - accuracy: 0.2990 - val_loss: 0.8547 - val_accuracy: 0.4545\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.2809 - accuracy: 0.2990 - val_loss: 0.8596 - val_accuracy: 0.4545\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2819 - accuracy: 0.3918 - val_loss: 0.8641 - val_accuracy: 0.4545\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.2336 - accuracy: 0.3402 - val_loss: 0.8621 - val_accuracy: 0.4545\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.2102 - accuracy: 0.4021 - val_loss: 0.8861 - val_accuracy: 0.4545\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.2429 - accuracy: 0.3711 - val_loss: 0.9271 - val_accuracy: 0.4545\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2136 - accuracy: 0.3918 - val_loss: 0.9870 - val_accuracy: 0.4545\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1940 - accuracy: 0.4433 - val_loss: 1.0616 - val_accuracy: 0.4545\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1928 - accuracy: 0.3505 - val_loss: 1.1293 - val_accuracy: 0.4545\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1881 - accuracy: 0.4330 - val_loss: 1.1786 - val_accuracy: 0.4545\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1821 - accuracy: 0.4124 - val_loss: 1.1866 - val_accuracy: 0.4545\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1899 - accuracy: 0.3711 - val_loss: 1.1914 - val_accuracy: 0.4545\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1870 - accuracy: 0.4124 - val_loss: 1.1993 - val_accuracy: 0.4545\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1525 - accuracy: 0.4124 - val_loss: 1.2130 - val_accuracy: 0.4545\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1780 - accuracy: 0.4433 - val_loss: 1.2536 - val_accuracy: 0.4545\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.1354 - accuracy: 0.4433 - val_loss: 1.3353 - val_accuracy: 0.4545\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1899 - accuracy: 0.3918 - val_loss: 1.4299 - val_accuracy: 0.4545\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1257 - accuracy: 0.4124 - val_loss: 1.5395 - val_accuracy: 0.4545\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1458 - accuracy: 0.4330 - val_loss: 1.5953 - val_accuracy: 0.4545\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1326 - accuracy: 0.4330 - val_loss: 1.6620 - val_accuracy: 0.4545\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.1110 - accuracy: 0.4330 - val_loss: 1.7412 - val_accuracy: 0.4545\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1192 - accuracy: 0.4227 - val_loss: 1.8084 - val_accuracy: 0.4545\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1303 - accuracy: 0.4227 - val_loss: 1.8665 - val_accuracy: 0.4545\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1200 - accuracy: 0.4536 - val_loss: 1.8932 - val_accuracy: 0.4545\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1132 - accuracy: 0.4536 - val_loss: 1.8913 - val_accuracy: 0.4545\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1222 - accuracy: 0.3918 - val_loss: 1.7624 - val_accuracy: 0.4545\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1339 - accuracy: 0.4433 - val_loss: 1.7038 - val_accuracy: 0.4545\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1193 - accuracy: 0.4536 - val_loss: 1.6572 - val_accuracy: 0.4545\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.1276 - accuracy: 0.4433 - val_loss: 1.7022 - val_accuracy: 0.4545\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0953 - accuracy: 0.4124 - val_loss: 1.7094 - val_accuracy: 0.4545\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0891 - accuracy: 0.4330 - val_loss: 1.6959 - val_accuracy: 0.4545\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0938 - accuracy: 0.4639 - val_loss: 1.6884 - val_accuracy: 0.4545\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0889 - accuracy: 0.4742 - val_loss: 1.6666 - val_accuracy: 0.4545\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0918 - accuracy: 0.4433 - val_loss: 1.6570 - val_accuracy: 0.4545\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0905 - accuracy: 0.4639 - val_loss: 1.6756 - val_accuracy: 0.4545\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.1027 - accuracy: 0.4124 - val_loss: 1.7360 - val_accuracy: 0.4545\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0849 - accuracy: 0.4536 - val_loss: 1.8255 - val_accuracy: 0.4545\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0776 - accuracy: 0.4639 - val_loss: 1.9324 - val_accuracy: 0.4545\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0901 - accuracy: 0.4433 - val_loss: 2.0280 - val_accuracy: 0.4545\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0714 - accuracy: 0.4639 - val_loss: 2.1191 - val_accuracy: 0.4545\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.1169 - accuracy: 0.4433 - val_loss: 2.1841 - val_accuracy: 0.4545\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0630 - accuracy: 0.4433 - val_loss: 2.2801 - val_accuracy: 0.4545\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0810 - accuracy: 0.4227 - val_loss: 2.3151 - val_accuracy: 0.4545\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0655 - accuracy: 0.4536 - val_loss: 2.3605 - val_accuracy: 0.4545\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0719 - accuracy: 0.4639 - val_loss: 2.3508 - val_accuracy: 0.4545\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0691 - accuracy: 0.4433 - val_loss: 2.2574 - val_accuracy: 0.4545\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1023 - accuracy: 0.4639 - val_loss: 2.1645 - val_accuracy: 0.4545\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0604 - accuracy: 0.4227 - val_loss: 2.1222 - val_accuracy: 0.4545\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0657 - accuracy: 0.4742 - val_loss: 2.0385 - val_accuracy: 0.4545\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0819 - accuracy: 0.4433 - val_loss: 2.0057 - val_accuracy: 0.4545\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0523 - accuracy: 0.4639 - val_loss: 2.0070 - val_accuracy: 0.4545\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0533 - accuracy: 0.4639 - val_loss: 1.9736 - val_accuracy: 0.4545\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0678 - accuracy: 0.4536 - val_loss: 2.0190 - val_accuracy: 0.4545\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.1170 - accuracy: 0.4433 - val_loss: 2.0811 - val_accuracy: 0.4545\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0597 - accuracy: 0.4433 - val_loss: 2.1697 - val_accuracy: 0.4545\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0623 - accuracy: 0.4433 - val_loss: 2.2357 - val_accuracy: 0.4545\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0578 - accuracy: 0.4433 - val_loss: 2.2528 - val_accuracy: 0.4545\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0614 - accuracy: 0.4227 - val_loss: 2.2712 - val_accuracy: 0.4545\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0836 - accuracy: 0.4742 - val_loss: 2.2565 - val_accuracy: 0.4545\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0570 - accuracy: 0.4639 - val_loss: 2.2530 - val_accuracy: 0.4545\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0689 - accuracy: 0.4639 - val_loss: 2.2411 - val_accuracy: 0.4545\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0504 - accuracy: 0.4536 - val_loss: 2.2268 - val_accuracy: 0.4545\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0680 - accuracy: 0.4330 - val_loss: 2.1977 - val_accuracy: 0.4545\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0581 - accuracy: 0.4330 - val_loss: 2.1921 - val_accuracy: 0.4545\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0495 - accuracy: 0.4742 - val_loss: 2.1903 - val_accuracy: 0.5455\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0495 - accuracy: 0.4639 - val_loss: 2.1987 - val_accuracy: 0.5455\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0751 - accuracy: 0.4227 - val_loss: 2.1987 - val_accuracy: 0.5455\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0433 - accuracy: 0.4433 - val_loss: 2.2084 - val_accuracy: 0.5455\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0471 - accuracy: 0.4536 - val_loss: 2.2096 - val_accuracy: 0.5455\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0589 - accuracy: 0.4639 - val_loss: 2.2237 - val_accuracy: 0.5455\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0500 - accuracy: 0.4742 - val_loss: 2.2302 - val_accuracy: 0.6364\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0485 - accuracy: 0.4639 - val_loss: 2.2090 - val_accuracy: 0.6364\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0522 - accuracy: 0.4433 - val_loss: 2.2075 - val_accuracy: 0.6364\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0584 - accuracy: 0.4433 - val_loss: 2.2522 - val_accuracy: 0.6364\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0744 - accuracy: 0.4536 - val_loss: 2.2752 - val_accuracy: 0.6364\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0664 - accuracy: 0.4433 - val_loss: 2.2832 - val_accuracy: 0.6364\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0421 - accuracy: 0.4536 - val_loss: 2.2929 - val_accuracy: 0.6364\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0452 - accuracy: 0.4433 - val_loss: 2.3031 - val_accuracy: 0.6364\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0530 - accuracy: 0.4433 - val_loss: 2.3072 - val_accuracy: 0.6364\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0462 - accuracy: 0.4639 - val_loss: 2.3186 - val_accuracy: 0.5455\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0559 - accuracy: 0.4536 - val_loss: 2.3771 - val_accuracy: 0.4545\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0535 - accuracy: 0.4639 - val_loss: 2.4411 - val_accuracy: 0.4545\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0430 - accuracy: 0.4536 - val_loss: 2.5118 - val_accuracy: 0.4545\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0559 - accuracy: 0.4536 - val_loss: 2.5736 - val_accuracy: 0.4545\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0917 - accuracy: 0.4433 - val_loss: 2.6119 - val_accuracy: 0.4545\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0475 - accuracy: 0.4639 - val_loss: 2.6569 - val_accuracy: 0.4545\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0492 - accuracy: 0.4536 - val_loss: 2.7418 - val_accuracy: 0.4545\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0596 - accuracy: 0.4536 - val_loss: 2.8005 - val_accuracy: 0.4545\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0385 - accuracy: 0.4433 - val_loss: 2.8468 - val_accuracy: 0.4545\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0526 - accuracy: 0.4433 - val_loss: 2.8817 - val_accuracy: 0.4545\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0403 - accuracy: 0.4536 - val_loss: 2.9072 - val_accuracy: 0.4545\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0368 - accuracy: 0.4536 - val_loss: 2.9060 - val_accuracy: 0.4545\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0479 - accuracy: 0.4433 - val_loss: 2.8645 - val_accuracy: 0.4545\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0386 - accuracy: 0.4639 - val_loss: 2.8284 - val_accuracy: 0.4545\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0453 - accuracy: 0.4536 - val_loss: 2.7794 - val_accuracy: 0.4545\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0396 - accuracy: 0.4536 - val_loss: 2.7378 - val_accuracy: 0.4545\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0356 - accuracy: 0.4536 - val_loss: 2.6821 - val_accuracy: 0.5455\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0330 - accuracy: 0.4433 - val_loss: 2.6445 - val_accuracy: 0.5455\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0544 - accuracy: 0.4639 - val_loss: 2.5580 - val_accuracy: 0.5455\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0364 - accuracy: 0.4536 - val_loss: 2.4803 - val_accuracy: 0.5455\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0266 - accuracy: 0.4536 - val_loss: 2.4304 - val_accuracy: 0.5455\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0609 - accuracy: 0.4536 - val_loss: 2.4140 - val_accuracy: 0.5455\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0353 - accuracy: 0.4742 - val_loss: 2.4053 - val_accuracy: 0.5455\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0391 - accuracy: 0.4639 - val_loss: 2.4179 - val_accuracy: 0.6364\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0321 - accuracy: 0.4536 - val_loss: 2.4657 - val_accuracy: 0.6364\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0342 - accuracy: 0.4536 - val_loss: 2.4766 - val_accuracy: 0.6364\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0322 - accuracy: 0.4742 - val_loss: 2.4895 - val_accuracy: 0.6364\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0338 - accuracy: 0.4536 - val_loss: 2.5075 - val_accuracy: 0.6364\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0385 - accuracy: 0.4536 - val_loss: 2.4947 - val_accuracy: 0.6364\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0280 - accuracy: 0.4639 - val_loss: 2.4803 - val_accuracy: 0.6364\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0225 - accuracy: 0.4639 - val_loss: 2.4699 - val_accuracy: 0.6364\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0392 - accuracy: 0.4227 - val_loss: 2.4683 - val_accuracy: 0.6364\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0338 - accuracy: 0.4742 - val_loss: 2.4765 - val_accuracy: 0.6364\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0379 - accuracy: 0.4742 - val_loss: 2.4914 - val_accuracy: 0.6364\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0265 - accuracy: 0.4742 - val_loss: 2.5027 - val_accuracy: 0.6364\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0312 - accuracy: 0.4536 - val_loss: 2.5216 - val_accuracy: 0.6364\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0584 - accuracy: 0.4639 - val_loss: 2.5180 - val_accuracy: 0.6364\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0259 - accuracy: 0.4742 - val_loss: 2.5169 - val_accuracy: 0.6364\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0263 - accuracy: 0.4639 - val_loss: 2.5121 - val_accuracy: 0.6364\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0334 - accuracy: 0.4330 - val_loss: 2.4997 - val_accuracy: 0.6364\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0358 - accuracy: 0.4639 - val_loss: 2.4854 - val_accuracy: 0.6364\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0336 - accuracy: 0.4639 - val_loss: 2.4754 - val_accuracy: 0.6364\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.4754 - accuracy: 0.6364\n",
      "Accuracy: 63.64%\n",
      "Saved gru_model to disk\n"
     ]
    }
   ],
   "source": [
    "gru_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, decay=0.01, epsilon=1e-7), metrics=['accuracy'])\n",
    "\n",
    "X_train = np.asarray(X_train).astype(np.int)\n",
    "y_train=np.asarray(y_train).astype(np.int)\n",
    "X_valid=np.asarray(X_valid).astype(np.int)\n",
    "y_valid=np.asarray(y_valid).astype(np.int)\n",
    "\n",
    "gru_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=150,\n",
    "    verbose=1,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "_, accuracy = gru_model.evaluate(X_valid, y_valid)\n",
    "acc = '%.2f' % (accuracy*100)\n",
    "print(f'Accuracy: {acc}%')\n",
    "\n",
    "gru_model.save(\"gru_model.h5\")\n",
    "gru_model.save_weights(\"gru_model_weights.h5\")\n",
    "print(\"Saved gru_model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.67769682e-01, 9.99444783e-01, 9.99964118e-01, 9.99991894e-01,\n",
       "        9.99996781e-01],\n",
       "       [1.48760516e-03, 9.07743561e-06, 5.86755164e-07, 1.37102617e-07,\n",
       "        6.92975846e-08],\n",
       "       [1.13580050e-03, 7.50711297e-06, 5.40555561e-07, 1.41185978e-07,\n",
       "        8.57501732e-08],\n",
       "       [9.59256709e-01, 9.99050200e-01, 9.99955416e-01, 9.99992013e-01,\n",
       "        9.99996185e-01],\n",
       "       [9.83258843e-01, 9.99823630e-01, 9.99995112e-01, 9.99999523e-01,\n",
       "        9.99999881e-01],\n",
       "       [9.63202238e-01, 9.99214649e-01, 9.99954462e-01, 9.99989152e-01,\n",
       "        9.99992132e-01],\n",
       "       [7.17637420e-04, 5.28736336e-06, 4.39200875e-07, 1.71790802e-07,\n",
       "        1.38955215e-07],\n",
       "       [4.51980717e-03, 3.84005871e-05, 1.60765774e-06, 2.76027748e-07,\n",
       "        1.20759552e-07],\n",
       "       [1.25847710e-02, 6.55307231e-05, 2.59866056e-06, 4.83915926e-07,\n",
       "        1.94566837e-07],\n",
       "       [9.96229589e-01, 9.99975562e-01, 9.99998689e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [9.93217647e-01, 9.99948859e-01, 9.99998212e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [9.94104981e-01, 9.99959946e-01, 9.99998450e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [9.95646298e-01, 9.99975681e-01, 9.99999046e-01, 9.99999881e-01,\n",
       "        9.99999881e-01],\n",
       "       [1.91650388e-03, 9.29454200e-06, 5.72177214e-07, 1.40647359e-07,\n",
       "        6.92118576e-08],\n",
       "       [9.97015953e-01, 9.99977827e-01, 9.99998927e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [5.09538781e-03, 2.74589111e-05, 1.44409728e-06, 3.28876979e-07,\n",
       "        2.03017763e-07],\n",
       "       [3.62193817e-03, 2.28229910e-05, 1.22698600e-06, 2.37796996e-07,\n",
       "        9.32470670e-08],\n",
       "       [2.07817508e-03, 1.30833032e-05, 7.72789463e-07, 1.88184870e-07,\n",
       "        1.08828651e-07],\n",
       "       [9.73775566e-01, 9.99515533e-01, 9.99946237e-01, 9.99981165e-01,\n",
       "        9.99992847e-01],\n",
       "       [1.67599332e-03, 1.07435462e-05, 7.52576909e-07, 1.82908551e-07,\n",
       "        8.34701481e-08],\n",
       "       [9.96982276e-01, 9.99974608e-01, 9.99998808e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [1.77334342e-03, 1.13443994e-05, 6.88248292e-07, 1.62772864e-07,\n",
       "        7.75405198e-08],\n",
       "       [9.73064244e-01, 9.99800622e-01, 9.99995232e-01, 9.99999523e-01,\n",
       "        9.99999881e-01],\n",
       "       [9.99794109e-04, 6.94829396e-06, 5.28330759e-07, 1.41092983e-07,\n",
       "        6.55275940e-08],\n",
       "       [9.97006953e-01, 9.99939799e-01, 9.99994516e-01, 9.99998689e-01,\n",
       "        9.99999523e-01],\n",
       "       [9.97830093e-01, 9.99985576e-01, 9.99999285e-01, 9.99999881e-01,\n",
       "        9.99999881e-01],\n",
       "       [2.46892474e-03, 1.19091455e-05, 6.27528550e-07, 1.51873877e-07,\n",
       "        8.48940047e-08],\n",
       "       [9.97953653e-01, 9.99986291e-01, 9.99999046e-01, 9.99999642e-01,\n",
       "        9.99999762e-01],\n",
       "       [9.94488299e-01, 9.99962449e-01, 9.99998689e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [1.43298358e-02, 1.66145051e-04, 1.52406246e-05, 2.54358338e-06,\n",
       "        8.04253943e-07],\n",
       "       [1.19902985e-03, 7.20231583e-06, 4.92666061e-07, 1.22605215e-07,\n",
       "        5.69983989e-08],\n",
       "       [9.96408522e-01, 9.99972343e-01, 9.99998093e-01, 9.99999523e-01,\n",
       "        9.99999642e-01],\n",
       "       [9.85750675e-01, 9.99852896e-01, 9.99994159e-01, 9.99998927e-01,\n",
       "        9.99999642e-01],\n",
       "       [9.56970274e-01, 9.98874843e-01, 9.99945760e-01, 9.99995947e-01,\n",
       "        9.99999404e-01],\n",
       "       [2.81634950e-03, 1.53200726e-05, 1.04800563e-06, 2.64874444e-07,\n",
       "        1.31174048e-07],\n",
       "       [3.58468900e-03, 1.82196509e-05, 9.98033329e-07, 2.21947943e-07,\n",
       "        1.01520747e-07],\n",
       "       [1.15189172e-01, 9.35351476e-04, 1.65609927e-05, 2.59176022e-06,\n",
       "        1.39833685e-06],\n",
       "       [9.95939493e-01, 9.99974608e-01, 9.99998808e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [9.32607278e-02, 6.02236427e-02, 1.14417460e-04, 2.24711471e-06,\n",
       "        4.93484777e-07],\n",
       "       [9.92965341e-01, 9.99913335e-01, 9.99995232e-01, 9.99999166e-01,\n",
       "        9.99999642e-01],\n",
       "       [9.91795242e-01, 9.99936342e-01, 9.99997497e-01, 9.99999642e-01,\n",
       "        9.99999881e-01],\n",
       "       [1.11245140e-02, 6.51746159e-05, 2.48846754e-06, 4.24766341e-07,\n",
       "        1.88879625e-07],\n",
       "       [3.50403711e-02, 1.92768406e-04, 8.65138463e-06, 3.08294852e-06,\n",
       "        3.50932146e-06],\n",
       "       [9.91772830e-01, 9.99952197e-01, 9.99998212e-01, 9.99999642e-01,\n",
       "        9.99999881e-01],\n",
       "       [8.71395767e-01, 9.87499654e-01, 9.99026060e-01, 9.99929667e-01,\n",
       "        9.99992371e-01],\n",
       "       [1.04666338e-03, 6.43404701e-06, 4.46764432e-07, 1.13312268e-07,\n",
       "        5.45180896e-08],\n",
       "       [9.98367131e-01, 9.99985576e-01, 9.99999166e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [1.25369139e-03, 7.42918337e-06, 4.93030825e-07, 1.22623348e-07,\n",
       "        5.79765533e-08],\n",
       "       [9.97702420e-01, 9.99982119e-01, 9.99999166e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [3.82295274e-03, 2.04475236e-05, 1.02786282e-06, 2.06240003e-07,\n",
       "        8.57284235e-08],\n",
       "       [8.16796068e-03, 4.59237381e-05, 1.79380504e-06, 2.79953497e-07,\n",
       "        9.80368497e-08],\n",
       "       [6.80311117e-04, 5.07685718e-06, 4.17364959e-07, 1.17006550e-07,\n",
       "        5.85442805e-08],\n",
       "       [9.97407496e-01, 9.99984026e-01, 9.99999166e-01, 9.99999881e-01,\n",
       "        9.99999881e-01],\n",
       "       [8.34208215e-04, 5.73410716e-06, 4.51637789e-07, 1.25179440e-07,\n",
       "        6.84203911e-08],\n",
       "       [9.91053998e-01, 9.99925852e-01, 9.99997377e-01, 9.99999642e-01,\n",
       "        9.99999881e-01],\n",
       "       [1.00412900e-02, 6.11547075e-05, 2.49450500e-06, 3.92359397e-07,\n",
       "        1.91275447e-07],\n",
       "       [9.81809735e-01, 9.99824345e-01, 9.99995351e-01, 9.99999523e-01,\n",
       "        9.99999881e-01],\n",
       "       [9.95588541e-01, 9.99969006e-01, 9.99998569e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [9.87657785e-01, 9.99910474e-01, 9.99997020e-01, 9.99999642e-01,\n",
       "        9.99999881e-01],\n",
       "       [8.71395767e-01, 9.87273216e-01, 9.99019504e-01, 9.99981284e-01,\n",
       "        9.99998808e-01],\n",
       "       [9.79346572e-04, 6.64134222e-06, 4.71665345e-07, 1.15712901e-07,\n",
       "        5.39874492e-08],\n",
       "       [9.86424387e-01, 9.99877334e-01, 9.99995828e-01, 9.99999404e-01,\n",
       "        9.99999762e-01],\n",
       "       [9.89472091e-01, 9.99937892e-01, 9.99998093e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [2.16135196e-03, 1.15594439e-05, 7.07942604e-07, 1.62160845e-07,\n",
       "        7.41378727e-08],\n",
       "       [1.63103780e-03, 9.30734222e-06, 6.16176806e-07, 1.61194251e-07,\n",
       "        9.21858572e-08],\n",
       "       [3.14638298e-03, 1.32984978e-05, 6.53185168e-07, 1.40347353e-07,\n",
       "        6.25596783e-08],\n",
       "       [9.97029543e-01, 9.99976993e-01, 9.99998808e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [9.94063437e-01, 9.99966741e-01, 9.99998808e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [1.28866907e-03, 8.82126733e-06, 7.01031411e-07, 1.85140166e-07,\n",
       "        1.31274277e-07],\n",
       "       [4.01993981e-03, 1.89597777e-05, 7.95282915e-07, 1.52195895e-07,\n",
       "        6.53979910e-08],\n",
       "       [9.97418404e-01, 9.99984384e-01, 9.99999166e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [9.96095121e-01, 9.99974012e-01, 9.99998927e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [1.21694594e-03, 8.69647465e-06, 6.39411269e-07, 1.55163647e-07,\n",
       "        7.22792919e-08],\n",
       "       [9.96940792e-01, 9.99979734e-01, 9.99998927e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [9.97372985e-01, 9.99984980e-01, 9.99999166e-01, 9.99999881e-01,\n",
       "        9.99999881e-01],\n",
       "       [9.46207285e-01, 9.98364151e-01, 9.99857306e-01, 9.99971509e-01,\n",
       "        9.99989271e-01],\n",
       "       [9.95163083e-01, 9.99958515e-01, 9.99998331e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [8.71395767e-01, 9.87499654e-01, 9.99026060e-01, 9.99907255e-01,\n",
       "        9.99986529e-01],\n",
       "       [9.93524075e-01, 9.99954581e-01, 9.99998093e-01, 9.99999642e-01,\n",
       "        9.99999881e-01],\n",
       "       [1.50521321e-03, 8.40424946e-06, 6.98541442e-07, 1.97472374e-07,\n",
       "        1.00846243e-07],\n",
       "       [9.92752790e-01, 9.99946117e-01, 9.99997854e-01, 9.99999642e-01,\n",
       "        9.99999881e-01],\n",
       "       [8.44505965e-04, 6.03753597e-06, 4.61763278e-07, 1.27678206e-07,\n",
       "        6.59004868e-08],\n",
       "       [1.53497653e-03, 9.02004103e-06, 5.81876520e-07, 1.39798459e-07,\n",
       "        6.33404653e-08],\n",
       "       [9.97225821e-01, 9.99982953e-01, 9.99999166e-01, 9.99999881e-01,\n",
       "        1.00000000e+00],\n",
       "       [9.92588222e-01, 9.99946475e-01, 9.99998331e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [1.46052288e-03, 8.06781918e-06, 5.02501848e-07, 1.20361278e-07,\n",
       "        5.70516931e-08],\n",
       "       [8.10381607e-04, 5.88023386e-06, 4.80309438e-07, 1.75883812e-07,\n",
       "        1.24007272e-07],\n",
       "       [9.89632487e-01, 9.99903560e-01, 9.99996662e-01, 9.99999523e-01,\n",
       "        9.99999881e-01],\n",
       "       [2.45305244e-03, 1.47390247e-05, 9.68753398e-07, 2.43105575e-07,\n",
       "        1.28584418e-07],\n",
       "       [9.96709108e-01, 9.99955058e-01, 9.99996901e-01, 9.99999404e-01,\n",
       "        9.99999881e-01],\n",
       "       [6.14987803e-04, 4.87180887e-06, 7.00314388e-07, 4.13571570e-07,\n",
       "        5.61380602e-07],\n",
       "       [1.79664511e-03, 1.07098913e-05, 6.92044580e-07, 2.06698203e-07,\n",
       "        1.72243901e-07],\n",
       "       [9.20537233e-01, 9.96206641e-01, 9.99848962e-01, 9.99988675e-01,\n",
       "        9.99997854e-01],\n",
       "       [1.33043434e-02, 8.50692595e-05, 4.28775002e-06, 6.52551307e-07,\n",
       "        2.08703128e-07],\n",
       "       [1.03184730e-02, 4.69908628e-05, 2.00336399e-06, 4.01854749e-07,\n",
       "        1.70874657e-07],\n",
       "       [9.97671783e-01, 9.99982834e-01, 9.99999046e-01, 9.99999762e-01,\n",
       "        9.99999881e-01],\n",
       "       [1.65444450e-03, 1.03720231e-05, 7.41609824e-07, 1.87128094e-07,\n",
       "        9.08791122e-08]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 70ms/step\n",
      "There are 51 truths and 46 lies.\n",
      "Average truth results: [0.9810392  0.9990345  0.9999308  0.99999464 0.99999875]\n",
      "Average lie results: [8.5480148e-03 1.3544103e-03 4.2632969e-06 4.2474946e-07 2.3889504e-07]\n"
     ]
    }
   ],
   "source": [
    "X_train_res = gru_model.predict(X_train)\n",
    "\n",
    "truth_res = []\n",
    "lie_res = []\n",
    "for xi, yi in zip(X_train_res, y_train):\n",
    "  if yi == 1:\n",
    "    truth_res.append(xi)\n",
    "  else:\n",
    "    lie_res.append(xi)\n",
    "print(f\"There are {len(truth_res)} truths and {len(lie_res)} lies.\")\n",
    "\n",
    "average_truth_res = np.mean(truth_res, axis=0)\n",
    "print(f\"Average truth results: {average_truth_res}\")\n",
    "average_lie_res = np.mean(lie_res, axis=0)\n",
    "print(f\"Average lie results: {average_lie_res}\")\n",
    "\n",
    "database={}\n",
    "database['truth'] = average_truth_res\n",
    "database['lie'] = average_lie_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "X_test.shape=(13, 300, 512)\n",
      "dist_truth=0.018212424591183662, dist_lie=2.2313032150268555\n",
      "dist_truth=1.4483065605163574, dist_lie=0.8385909199714661\n",
      "dist_truth=0.012135105207562447, dist_lie=2.228574752807617\n",
      "y_predict:  1 y:  0\n",
      "dist_truth=2.2123146057128906, dist_lie=0.025451812893152237\n",
      "y_predict:  0 y:  1\n",
      "dist_truth=0.01745789870619774, dist_lie=2.2309646606445312\n",
      "dist_truth=1.7026264667510986, dist_lie=1.3191823959350586\n",
      "dist_truth=0.015915647149086, dist_lie=2.230267286300659\n",
      "y_predict:  1 y:  0\n",
      "dist_truth=0.11793786287307739, dist_lie=2.1705970764160156\n",
      "dist_truth=0.22634011507034302, dist_lie=2.1193361282348633\n",
      "y_predict:  1 y:  0\n",
      "dist_truth=0.008574393577873707, dist_lie=2.2270028591156006\n",
      "dist_truth=2.2176380157470703, dist_lie=0.0131016094237566\n",
      "y_predict:  0 y:  1\n",
      "dist_truth=1.042024850845337, dist_lie=1.6041048765182495\n",
      "dist_truth=2.226774215698242, dist_lie=0.007744119502604008\n",
      "Validation accuracy: 61.54%\n"
     ]
    }
   ],
   "source": [
    "X_test_res = gru_model.predict(X_test)\n",
    "print(f\"X_test.shape={X_test.shape}\")\n",
    "\n",
    "def verify(res, gru_model, database):\n",
    "    dist_truth = np.linalg.norm(res - database[\"truth\"])\n",
    "    dist_lie = np.linalg.norm(res - database[\"lie\"])\n",
    "    print(f\"dist_truth={dist_truth}, dist_lie={dist_lie}\")\n",
    "    return 1 if dist_truth < dist_lie else 0\n",
    "\n",
    "count = 0\n",
    "y_pred = []\n",
    "\n",
    "for res, y in zip(X_test_res, y_test):\n",
    "    y_predict = verify(res, gru_model, database)\n",
    "    y_pred.append(y_predict)\n",
    "    if y_predict == y:\n",
    "        count += 1\n",
    "    else:\n",
    "        print(\"y_predict: \", y_predict, \"y: \", y)\n",
    "\n",
    "accuracy = count/X_test_res.shape[0]\n",
    "acc_str = '%.2f' % (accuracy*100)\n",
    "print('Validation accuracy: ' + acc_str + '%')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('mlajcomp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14295adcff452caf29adbf0d23e621f3703eadedbf55481088c4666923b22c47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
